Using GloVe embeddings
Found 400000 word vectors.
Build Model
2018-08-17 11:40:50.829193: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-08-17 11:40:50.950648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-08-17 11:40:50.951026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:28:00.0
totalMemory: 7.93GiB freeMemory: 7.41GiB
2018-08-17 11:40:50.951043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:28:00.0, compute capability: 6.1)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 8)                 0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 8, 200)            6000200   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 100)               75300     
=================================================================
Total params: 6,075,500
Trainable params: 6,075,500
Non-trainable params: 0
_________________________________________________________________
None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 8, 8)              0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 8, 100)            6075500   
_________________________________________________________________
bidirectional_2 (Bidirection (None, 100)               45300     
=================================================================
Total params: 6,120,800
Trainable params: 6,120,800
Non-trainable params: 0
_________________________________________________________________
None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         (None, 8, 8, 8)           0         
_________________________________________________________________
time_distributed_2 (TimeDist (None, 8, 100)            6120800   
_________________________________________________________________
bidirectional_3 (Bidirection (None, 100)               45300     
_________________________________________________________________
dense_1 (Dense)              (None, 5)                 505       
=================================================================
Total params: 6,166,605
Trainable params: 6,166,605
Non-trainable params: 0
_________________________________________________________________
None
SRNN.py:166: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.
  verbose = 1)
Train on 374887 samples, validate on 46861 samples
Epoch 1/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.9703 - acc: 0.5757Epoch 00001: val_acc improved from -inf to 0.64538, saving model to biSRNN(8,2)_yelp2013.h5
374887/374887 [==============================] - 530s 1ms/step - loss: 0.9702 - acc: 0.5758 - val_loss: 0.8170 - val_acc: 0.6454
Epoch 2/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.8348 - acc: 0.6351Epoch 00002: val_acc improved from 0.64538 to 0.65675, saving model to biSRNN(8,2)_yelp2013.h5
374887/374887 [==============================] - 524s 1ms/step - loss: 0.8348 - acc: 0.6351 - val_loss: 0.7824 - val_acc: 0.6568
Epoch 3/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.7989 - acc: 0.6513Epoch 00003: val_acc improved from 0.65675 to 0.66204, saving model to biSRNN(8,2)_yelp2013.h5
374887/374887 [==============================] - 524s 1ms/step - loss: 0.7989 - acc: 0.6513 - val_loss: 0.7698 - val_acc: 0.6620
Epoch 4/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.7769 - acc: 0.6607Epoch 00004: val_acc did not improve
374887/374887 [==============================] - 528s 1ms/step - loss: 0.7769 - acc: 0.6607 - val_loss: 0.7813 - val_acc: 0.6556
Epoch 5/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.7593 - acc: 0.6680Epoch 00005: val_acc improved from 0.66204 to 0.66795, saving model to biSRNN(8,2)_yelp2013.h5
374887/374887 [==============================] - 527s 1ms/step - loss: 0.7593 - acc: 0.6680 - val_loss: 0.7597 - val_acc: 0.6680
Epoch 6/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.7438 - acc: 0.6766Epoch 00006: val_acc did not improve
374887/374887 [==============================] - 525s 1ms/step - loss: 0.7438 - acc: 0.6766 - val_loss: 0.7670 - val_acc: 0.6624
Epoch 7/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.7322 - acc: 0.6823Epoch 00007: val_acc did not improve
374887/374887 [==============================] - 525s 1ms/step - loss: 0.7322 - acc: 0.6823 - val_loss: 0.7603 - val_acc: 0.6659
Epoch 8/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.7203 - acc: 0.6881Epoch 00008: val_acc did not improve
374887/374887 [==============================] - 536s 1ms/step - loss: 0.7203 - acc: 0.6881 - val_loss: 0.7628 - val_acc: 0.6653
Epoch 9/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.7101 - acc: 0.6928Epoch 00009: val_acc did not improve
374887/374887 [==============================] - 532s 1ms/step - loss: 0.7101 - acc: 0.6928 - val_loss: 0.7685 - val_acc: 0.6657
Epoch 10/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.7010 - acc: 0.6979Epoch 00010: val_acc did not improve
374887/374887 [==============================] - 533s 1ms/step - loss: 0.7009 - acc: 0.6979 - val_loss: 0.7767 - val_acc: 0.6629
46860/46860 [==============================] - 11s 229us/step
[0.7667065569339936, 0.6644046099024149]
