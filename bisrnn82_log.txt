Using GloVe embeddings
Found 400000 word vectors.
Build Model
2018-08-17 09:53:23.706267: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-08-17 09:53:23.822113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-08-17 09:53:23.822506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:28:00.0
totalMemory: 7.93GiB freeMemory: 7.36GiB
2018-08-17 09:53:23.822526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:28:00.0, compute capability: 6.1)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 8)                 0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 8, 200)            6000200   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 100)               75300     
=================================================================
Total params: 6,075,500
Trainable params: 6,075,500
Non-trainable params: 0
_________________________________________________________________
None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 8, 8)              0         
_________________________________________________________________
time_distributed_1 (TimeDist (None, 8, 100)            6075500   
_________________________________________________________________
bidirectional_2 (Bidirection (None, 100)               45300     
=================================================================
Total params: 6,120,800
Trainable params: 6,120,800
Non-trainable params: 0
_________________________________________________________________
None
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         (None, 8, 8, 8)           0         
_________________________________________________________________
time_distributed_2 (TimeDist (None, 8, 100)            6120800   
_________________________________________________________________
bidirectional_3 (Bidirection (None, 100)               45300     
_________________________________________________________________
dense_1 (Dense)              (None, 5)                 505       
=================================================================
Total params: 6,166,605
Trainable params: 6,166,605
Non-trainable params: 0
_________________________________________________________________
None
SRNN.py:166: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.
  verbose = 1)
Train on 374887 samples, validate on 46861 samples
Epoch 1/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.8426 - acc: 0.6289Epoch 00001: val_acc improved from -inf to 0.66936, saving model to biSRNN(8,2)_yelp2013.h5
374887/374887 [==============================] - 479s 1ms/step - loss: 0.8426 - acc: 0.6289 - val_loss: 0.7514 - val_acc: 0.6694
Epoch 2/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.7150 - acc: 0.6877Epoch 00002: val_acc improved from 0.66936 to 0.67775, saving model to biSRNN(8,2)_yelp2013.h5
374887/374887 [==============================] - 475s 1ms/step - loss: 0.7150 - acc: 0.6877 - val_loss: 0.7332 - val_acc: 0.6777
Epoch 3/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.6426 - acc: 0.7220Epoch 00003: val_acc did not improve
374887/374887 [==============================] - 478s 1ms/step - loss: 0.6426 - acc: 0.7219 - val_loss: 0.7655 - val_acc: 0.6738
Epoch 4/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.5573 - acc: 0.7622Epoch 00004: val_acc did not improve
374887/374887 [==============================] - 482s 1ms/step - loss: 0.5573 - acc: 0.7622 - val_loss: 0.8155 - val_acc: 0.6632
Epoch 5/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.4599 - acc: 0.8083Epoch 00005: val_acc did not improve
374887/374887 [==============================] - 482s 1ms/step - loss: 0.4599 - acc: 0.8083 - val_loss: 0.9654 - val_acc: 0.6471
Epoch 6/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.3663 - acc: 0.8506Epoch 00006: val_acc did not improve
374887/374887 [==============================] - 479s 1ms/step - loss: 0.3663 - acc: 0.8506 - val_loss: 1.2152 - val_acc: 0.6347
Epoch 7/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.2972 - acc: 0.8816Epoch 00007: val_acc did not improve
374887/374887 [==============================] - 486s 1ms/step - loss: 0.2972 - acc: 0.8817 - val_loss: 1.3336 - val_acc: 0.6269
Epoch 8/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.9034Epoch 00008: val_acc did not improve
374887/374887 [==============================] - 481s 1ms/step - loss: 0.2451 - acc: 0.9034 - val_loss: 1.5463 - val_acc: 0.6273
Epoch 9/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.2113 - acc: 0.9174Epoch 00009: val_acc did not improve
374887/374887 [==============================] - 481s 1ms/step - loss: 0.2113 - acc: 0.9174 - val_loss: 1.7766 - val_acc: 0.6175
Epoch 10/10
374800/374887 [============================>.] - ETA: 0s - loss: 0.1858 - acc: 0.9283Epoch 00010: val_acc did not improve
374887/374887 [==============================] - 484s 1ms/step - loss: 0.1858 - acc: 0.9283 - val_loss: 1.8478 - val_acc: 0.6150
46860/46860 [==============================] - 8s 166us/step
[0.7416473632687134, 0.6732821183686983]

